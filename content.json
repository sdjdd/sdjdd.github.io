{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"sdjdd","url":"https://blog.sdjdd.com","root":"/"},"posts":[{"title":"Dockerfile最佳实践","slug":"Dockerfile最佳实践","date":"2019-07-21T08:24:59.000Z","updated":"2019-07-25T03:52:37.733Z","comments":true,"path":"2019/07/21/Dockerfile最佳实践/","link":"","permalink":"https://blog.sdjdd.com/2019/07/21/Dockerfile最佳实践/","excerpt":"","text":"原文链接：Intro Guide to Dockerfile Best Practices 如今，GitHub 上有超过一百万个 Dockerfiles，但并非所有 Dockerfiles 都是按照相同的方式创建的。效率是关重要，这系列文章将覆盖 Dockerfile 最佳实践的五个方面，帮助你编写更好的 Dockerfile ：优化构建时间、镜像大小、可维护性、安全性和复用性。如果你是 Docker 新手，这第一篇文章就是为你准备的！下一篇文章将涵盖更多高级内容。 重要提示：下列 Dockerfiles 要构建一个基于 Maven 的 Java 示例，我们将不断改进它。因此，最后一个 Dockerfile 是推荐的写法，而所有中间的文件只是为了说明特定的最佳实践。 优化构建时间在开发周期中，构建 Docker 镜像，修改代码，然后重新构建时，利用缓存非常重要。缓存有助于避免运行不必要的构建步骤。 提示1：缓存的顺序很重要 构建步骤（ Dockerfile 指令）的顺序很重要，因为当一个步骤的缓存因更改文件或修改 Dockerfile 中的行失效时，其缓存的后续步骤将中断。按照更改的频率从小到大排序你的步骤，以此优化缓存。 提示2：更明确的 COPY 减少缓存崩溃 只复制所需内容。如果可能的话，避免“COPY”。当把文件复制到镜像中时，确保你对要复制的内容十分明确。对被复制的文件的任何更改都会破坏缓存。在上面的例子中，只有预构建的 jar 应用需要被复制到镜像中，所以只复制它。这样对不相关文件的更改不会影响到缓存。 提示3：关联可缓存单元，例如 apt-get update &amp; install 每个 RUN 指令都可以看作是一个可缓存的单元，过多的 RUN 指令是不必要的，而将所有的命令链接到一个 RUN 指令中很容易破坏缓存，从而影响开发周期。当从包管理器安装包时，你总是希望把更新索引和安装包放在一个 RUN 命令里：它们组成了一个可缓存单元。否则就会有安装过期包的风险。 减小镜像大小镜像大小很重要，因为较小的镜像意味着更快的部署和较小的攻击面。 提示4：移除不必要的依赖 移除不必要的依赖项，不要安装调试工具。如果确实需要调试工具，可以稍后安装。某些包管理器（如 apt ）会自动安装用户指定包的推荐版本，从而占用不必要空间。Apt 有 -no-install-recommends 标志，可以确保不安装实际不需要的依赖项。如果确实需要，请明确添加。 提示5：移除包管理器缓存 包管理器有自己的缓存，可能会保留到镜像中。处理此问题的一种方法是在安装包的 RUN 指令中将其移除。在另一条 RUN 指令中移除并不会减小镜像大小。 还有其他方法可以减小镜像大小，比如文末介绍的多阶段构建。下一组最佳实践将着眼于如何优化 Dockerfile 的可维护性、安全性和可复用性。 可维护性提示6：尽可能使用官方镜像 官方镜像可以节省大量维护时间，因为所有安装步骤都已完成且应用了最佳实践。如果你有多个项目，它们可以共享这些层，因为它们使用完全相同的基础镜像。 提示7：使用更具体的标签 不要使用 latest 标签，它的便利之处在于：官方镜像总是能够在 Docker Hub 上使用。但随着时间的推移，可能会出现破坏性的更改。根据不使用缓存重新构建 Dockerfile 的时间间隔，构建可能失败。 相反，应该对基本镜像使用更具体的标签。在本例中，我们使用 openjdk 。还有很多可用的标签，查看 Docker Hub 文档，其中列出了该镜像的所有不同版本。 提示8：寻找最小版本 这些标签中有最小版本意味着其镜像也会更小。slim 版本基于一个简化的 Debian ，而 alpine 版本基于更小的 Alpine Linux 发行版镜像。一个显著的区别是，debian 仍然使用 GUN libc 而 alpine 使用 musl libc ，尽管后者要小得多，但在某些情况下可能导致兼容性问题。对于 openjdk ，jre 版本只包含 java 运行时，而不包含 sdk ；这也大大降低了镜像大小。 再生性到目前为止，上面的 Dockerfiles 都是假定您的 jar 包是在宿主机上构建的。这并不理想，因为你失去了容器提供的一致性环境的好处。例如，如果你的 Java 应用依赖于特定的库，那么由于构建应用的计算机不同，可能会带来不一致性。 提示9：在一致的环境中构建源代码是你想构建的 Docker 镜像的真实来源。Dockerfile 只是一个蓝图。 你应该首先确定所构建应用的全部所需内容。我们的 Java 应用需要 Maven 和 JDK ，所以我们基于 Docker Hub 中的一个特定的最小官方 Maven 镜像编写 Dockerfile ，该镜像包括 JDK 。如果需要更多的依赖项，可以在 RUN 步骤安装。 pom.xml 和 src 目录将被复制，它们是最终生成 app.jar 的 RUN 步骤所必需的。（ -e 标志显示错误，-B 标志以被称为 “batch” 的非交互模式运行）。 我们解决了环境不一致的问题，但引入了另一个问题：每次更改代码时，都会获取 pom.xml 中的所有依赖项。请看下一个提示。 提示10：在单独的步骤中获取依赖 还记得“可缓存单元”吗，我们可以把获取依赖项放在单独的可缓存单元中，只需要在 pom.xml 而不是源代码的更改时重新获取。两个 COPY 步骤之间的 RUN 步骤告诉Maven只获取依赖项。 在一致的环境中构建还引入了另外一个问题：我们的镜像比之前更大了，因为它包含运行时不需要的构建时依赖项。 提示11：使用多阶段构建来删除构建依赖（推荐的 Dockerfile） 多阶段构建的标志是使用多个 FROM 语句。每个 FROM 开启一个新的阶段。可以用 AS 关键字命名，我们用它来将第一阶段命名为 “builder”，便于稍后引用。它将在一致的环境中包含所有构建依赖项。 第二阶段是我们的最终阶段，将产生最终镜像。它将严格满足运行时的要求，在本例中是基于Alpine 的最小 JRE（Java运行时）。中间阶段 builder 将被缓存但不会出现在最终镜像中。为了在最终镜像中生成构件，请使用 COPY --from=STAGE_NAME 。在本例中，STAGE_NAME 是 builder。 多阶段构建是消除构建时依赖性的首选解决方案。 我们经历了从不一致地构件臃肿的镜像到在一致环境中构建缓存友好的最小镜像。在下一篇博客文章中，我们将更多地介绍多阶段构建的其他用途。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sdjdd.com/categories/翻译/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.sdjdd.com/tags/Docker/"}]},{"title":"我不想成为一个全栈开发者","slug":"我不想成为一个全栈开发者","date":"2019-06-30T04:32:04.000Z","updated":"2019-07-21T08:57:17.731Z","comments":true,"path":"2019/06/30/我不想成为一个全栈开发者/","link":"","permalink":"https://blog.sdjdd.com/2019/06/30/我不想成为一个全栈开发者/","excerpt":"","text":"原文链接：I don’t want to be a full-fullstack developer译注：我很同意这为乌克兰开发者的观点，但他的英文水平实在是一言难尽。 我是一名 Ruby 开发者，一个全站 web 开发者。对此我深感疲惫，厌倦了有时负责商业分析和手册的质量保证。随着时间的推移，这个行业越来越多的依靠以开发人员为中心的工作流程，开发者们将越来越多的工作交由同一个人负责。 很久以前的互联网很久以前就有 DBA ，但现在几乎看不到了。在 Indeed.com 中搜索 全栈开发者 会得到 7000 个结果，web 开发者 的搜索结果有 40000 个。用户体验工程师和前端开发者的角色也在工作内容基本一致的前提下慢慢融合。越来越多的代理机构开始寻找既能做前端也能做后端的人，既能参与业务需求开发也能编写单元测试和集成测试的人，希望他们无所不在，无所不能。 削减成本乍一看，这似乎是个好主意，有人知道从开发到发布所需的一切，掌控整个过程。这对企业来说更加容易：你只需和一个人进行核对，开发过程不会因为“谁做什么”的问题而变得特别复杂。这么做还能降低成本，在质量和开发时间中作出一点权衡。沟通也变得更加顺畅了，和一个经历了整个开发流程的人交流要比沿着流程链挨个询问要容易得多。这听起来很不错，如果你不知道把这么多专业工作全都塞给一个人去做会发生什么的话。 复杂性的回击后端开发是个复杂的领域，包括理解网络层、服务器的整体工作方式、部署、AWS/Google/Azure 服务（它们对现代 web 应用至关重要）、编程语言和框架的细节，使用的协议、身份认证、数据库连接和配置等。前端包括过硬的 web 标准知识、浏览器间的差异、ES5、ES6、CSS、HTML、框架、预处理器、转换器、构建工具、UX、UI、浏览器角度的网络、浏览器存储，有时甚至包括 Flutter、Ionic 和 React Native 之类的移动端应用的细节。我不想讨论业务分析师和 QA 的角色，它们完全是不同的概念。 宽度还是广度？别误会，我认为扩大知识领域并通过对周边技术的理解更好的完成所在部门的工作是件好事。但不论行业，让开发者直接负责代码质量、选择解决方案以及项目开发的未来规划未必是件好事。我们大脑的空间是有限的。我们可以用一个或少数几个领域的更深更好的知识来填充它，或是多个领域的肤浅的知识。后者制造了一种虚假的自信，从而导致选择糟糕的解决方案，造轮子、选错技术、用显微镜敲钉子。 并非所有削减都是好的全栈很有趣，因为它似乎只存在于软件工程领域。其他领域大多都分工明确。你不会希望让牙医来治疗你的心脏，让神经外科医生来修复你的痔疮。它被用于软件工程似乎是由该领域的虚拟和故障安全特性。你的代码质量不会直接影响用户可见的结果，因此你在事情变糟之前有足够的时间处理（这种情况在你不在的时候常常出现）。此外，这个想法似乎对直观的金钱花销很有吸引力，雇佣拥有广泛技能（无论质量）的人可能看上去是在用同样的钱做更多的事。 我们得到的平庸的解决方案都是由那些在特定领域没有足够的专业知识，无法找出更好的方案的人提出的，他们粗略的知识中满是 Stackoverflow 的答案和复制粘贴来的东西。我们让那些不思进取的人不得不跟上太多主题，让那些专业人士无法创造出惊人的东西，因为他们没有足够的时间深究并创造出对该领域有价值的东西。在开发过程中不可避免的会遇到各种问题，导致 bug 和用户流失，影响开发成本，使我们以低廉的价格开发出不合格的产品。从短期经济角度来看，全栈可能是值得的，但它对整个行业和我们建设的项目都有害。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sdjdd.com/categories/翻译/"}],"tags":[]},{"title":"为什么我们改用 gRPC","slug":"为什么我们改用-gRPC","date":"2019-06-22T08:34:38.000Z","updated":"2019-06-23T12:10:32.487Z","comments":true,"path":"2019/06/22/为什么我们改用-gRPC/","link":"","permalink":"https://blog.sdjdd.com/2019/06/22/为什么我们改用-gRPC/","excerpt":"","text":"原文链接：Why We’re Switching to gRPC 本文由 Levin Fritz 于2019年5月27日发布。 当你使用微服务架构时，你需要做一个非常基本的决定：你的服务之间如何互相通信？默认的选择似乎是通过 HTTP 发送 JSON ——使用所谓的 REST APIs，尽管大多数人并不认真对待 REST 原则。在 fromAtoB 我们就是这么开始的。但最近我们决定将 gRPC 作为我们的标准。 gRPC 是由谷歌开发的远程过程调用系统，现已开源。尽管它已经存在了很多年，但我很少在网上看到关于为什么人们使用或不使用它的信息，所以我决定写一篇文章来解释我们使用 gRPC 的原因。 gRPC 的一个显著优势是它使用了一种高效的二进制编码，这使它比 JSON/HTTP 更快。虽然越快越好，但对我们来说有两个方面更为重要：清晰的接口规范和对流的支持。 gRPC 接口规范当你创建一个新的 gRPC 服务时，第一步始终是在一个 .proto 文件中定义接口。下面的代码展示了它的样子——它是我们一小部分 API 的简化版本。该示例定义了一个远程过程调用 “Lookup” 和其输入输出的类型。 12345678910111213141516171819202122syntax = \"proto3\";package fromatob;// FromAtoB 是 fromAtoB 后端 API 的简化版本。service FromAtoB &#123; rpc Lookup(LookupRequest) returns (Coordinate) &#123;&#125;&#125;// LookupRequest 是一个按名称查找城市坐标的请求。message LookupRequest &#123; string name = 1;&#125;// Coordinate 坐标通过经纬度来确定地球上的位置。message Coordinate &#123; // Latitude 是位置的纬度，范围是 [-90, 90]。 double latitude = 1; // Longitude 是位置的经度，范围是 [-180, 180]。 double longitude = 2;&#125; 通过这个文件，你可以用 protoc 编译器生成客户端和服务器代码，并开始编写提供或使用 API 的代码。 所以，为什么这是件好事而不仅仅是额外工作呢？再看一眼上面的示例代码。即使你从未使用过 gRPC 或 Protocol Buffers，它也非常易读：例如，很明显，要发送 Lookup 请求，你应该发送一个 name（一个字符串），然后得到一个 Coordinate（由 latitude 和 longitude 组成）。事实上，你可以像本示例一样通过添加一些简单的注释，将 .proto 文件变成 API 服务的文档。 当然，真实服务的规格要大得多，但不会复杂的多。不过就是多为方法提供些 rpc 声明，为数据类型提供些 message 声明。 通过 protoc 生成的代码还确保客户端或服务器发送的数据符合规范。这为调试提供了很大的帮助。我记得有两次，我正在处理生成错误格式的 JSON 数据的服务，因为该格式没在任何地方做验证，所以问题只出现在了用户界面。找出问题的唯一方式就是调试前端 JavaScript 代码——这对从来没用过前端 JavaScript 框架的后端工程师来说绝非易事！ Swagger / OpenAPI原则上，通过使用 Swagger 或 OpenAPI，HTTP/JSON 也可以获得同样的优点。这有个和上面 gRPC API 等效的示例： 123456789101112131415161718192021222324252627282930313233343536373839404142openapi: 3.0.0info: title: fromAtoB 后端 API 的简化版本 version: '1.0'paths: /lookup: get: description: 按名称查找城市坐标。 parameters: - in: query name: name schema: type: string description: City name. responses: '200': description: OK content: application/json: schema: $ref: '#/components/schemas/Coordinate' '404': description: Not Found content: text/plain: schema: type: stringcomponents: schemas: Coordinate: type: object description: Coordinate 坐标通过经纬度来确定地球上的位置。 properties: latitude: type: number description: Latitude 是位置的纬度，范围是 [-90, 90]。 longitude: type: number description: Longitude 是位置的经度，范围是 [-180, 180]。 将其与上面 gRPC 的规范进行比较。OpenAPI 的易读性更差！它更冗长，结构也更复杂（8个缩进级别，gRPC 只有1个）。 使用 OpenAPI 规范进行验证也比使用 gRPC 更困难。至少对内部服务来说，这意味着要么根本没写，要么跟不上 API 的发展而变得无用。 Streaming今年早些时候，我开始为我们的搜索设计新的 API（比如“获取2019年6月1日从柏林到巴黎的所有连接”）。我用 HTTP 和 JSON 构建了第一版 API 之后，我的一位同事指出某些情况下我们需要流式传输结果，这意味着我们应该在得到第一个结果的同时把他们发送出去。我的 API 仅仅返回一个 JSON 数组，所以在集齐所有结果之前，服务器不会发送任何数据。 我们通过在前端轮询的方式使用 API 。通过发送 POST 请求的方式设置搜索，然后发送重复的 GET 请求检索结果。响应中包含指示搜索是否完成的字段。这么做可行，但不是特别优雅，它需要服务器使用 Redis 之类的来存储中间结果。新的 API 将由多个更小的服务实现，我不想强制它们实现此逻辑。 这时我们准备尝试 gRPC 。要用 gRPC 发送远程过程调用的结果，只需在 .proto 文件中添加 stream 关键字。以下是 Search 函数的定义： 1rpc Search (SearchRequest) returns (stream Trip) &#123;&#125; protoc 编译器生成的代码包含一个具有 Send 函数的对象和一个具有 Recv 函数的对象，我们的服务器代码通过调用 Send 该函数逐一发送 Trip 对象，客户端代码通过调用 Recv 函数来检索它们。从程序员的角度来看，这比实现轮询 API 要容易的多。 警告我想提一些 gRPC 的缺点。它们都和工具有关，而不是协议本身。 当使用 HTTP/JSON 构建 API 时，可以使用 curl 、httpie 或 Postman 进行简单的手动测试。gRPC 也有一个类似的工具叫 grpcurl ，但它不是开箱即用的：你必须在服务器端添加 gRPC server reflection 扩展或为每个命令指定 .proto 文件。我们发现在服务器中添加一个小命令行工具可以更方便的发送简单请求。protoc 生成的客户端代码也使这非常简单。 对我们来说，更大的问题是我们在 HTTP 服务中使用的 Kubernetes 负载均衡器在 gRPC 中不能很好地工作。本质上，gRPC 要求在应用程序级别而不是 TCP 连接级别进行负载均衡。为了解决这个问题，我们按照这个教程：gRPC Load Balancing on Kubernetes without Tears 设置了 Linkerd。 结论尽管构建 gRPC API 需要多做一点前期工作，但我们发现具有明确的 API 规范和对流式传输的良好支持可以弥补这一点。对我们来说，gRPC 将成为我们构建的任何新的内部服务的默认选项。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sdjdd.com/categories/翻译/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"https://blog.sdjdd.com/tags/gRPC/"}]},{"title":"JSON 配置文件的缺点","slug":"JSON-配置文件的缺点","date":"2019-06-16T05:11:46.000Z","updated":"2019-06-16T16:53:59.849Z","comments":true,"path":"2019/06/16/JSON-配置文件的缺点/","link":"","permalink":"https://blog.sdjdd.com/2019/06/16/JSON-配置文件的缺点/","excerpt":"","text":"原文链接：The downsides of JSON for config files 我近期目睹了使用 JSON 作为配置文件的趋势，我认为这不是一个好主意。 这不是 JSON 的设计目的，因此它不擅长做这件事。JSON 旨在成为一种“轻量数据交换格式”，并声称其“易于人类读写”和“易于机器解析和生成”。 作为一种数据交换格式，JSON 相当不错。人类可以相对容易地读写它，而且机器解析起来也很容易（尽管存在一些问题）。 这是一个良好的在机器可读和人类可读之间的权衡，对于许多用例来说，这是对 XML 的一个很好的改进。 将其用于其它目的有些类似于：“嘿，这把锤子非常适合用来钉钉子！我很中意它！为什么不用它来敲这颗螺丝呢！”。当然，这么做也可以，但它不是正确的工具。 截止到目前，最大的问题是你无法添加注释。少数 JSON 解析器可以，但大多数都不支持，它也不在标准中。有充分的理由关于明确从 JSON 中移除注释。 你想要添加注释的原因有很多：记录为什么设置成该值，添加助记符或描述警告，警告过去的配置错误，在其中保留一个基本的更改日志，或者单纯是为了在调试时注释掉某个段落或值。 一个变通方法是添加一个新的键（如 {&quot;__comment&quot;: &quot;a comment&quot;, &quot;actual_data&quot;: &quot;...&quot;}，但我觉得这实在是太难看了)。 你也可以使用提交日志，但是谁会在提交历史中不大可能隐藏一些重要信息的情况下去仔细阅读它呢？ 一些 JSON 方言例如 JSON5，Hjson 和 HOCON 添加了对注释的支持，一些 JSON 解析器也是如此。这很好，我也鼓励你去使用它，但这不再是 JSON 了，而是 JSON 方言。这篇文章是关于 JSON 的，不是它的方言。 我还发现在手动编辑 JSON 时的体验很不理想，你需要频繁的追加逗号，引号的语义非常烦人，而且它缺乏使用多行字符串的能力。这些属性适用于 JSON 的预期用途，但不太适合编写配置文件。它可行吗？当然。有趣吗？不。 我也没觉得它特别易读，因为它包含过多的引号和其它语法噪音。我坦率承认这可能是我的品位问题。 JSON 是一种声明性配置语言。声明性配置（DC）适用于某些问题，但其它问题就不那么适用了。尤其是使用 DC 来控制逻辑，通常不是个好主意。 促使我写这篇文章的是 MediaWiki 的新扩展系统，旧系统使用一个简单的 PHP 文件来连接核心 MediaWiki 代码，加载所需依赖等。这些在新系统中被一个 JSON 文件替换。丧失了巧妙解决与其它插件或逻辑的兼容问题的能力。 它实现起来也很复杂，以前只需要 require(&#39;plugin/foo/plugin.php&#39;);，现在它需要解析一个 JSON 文件，并根据其内容做些什么。这要复杂得多，因此也难以测试。 而使用 JSON 文件存储基本的元数据是有意义的（更容易在网站上解析和显示），用它来描述代码的工作方式对于我来说是对 DC 的滥用。毕竟这是代码的活儿。 很多人向我征求关于使用什么的建议。这不是个容易回答的问题，因为它取决于你的用例，编程语言，库环境和社会因素。没有单一的“正确答案”，也许只有“最简单的，满足你所有需求”的答案。事实上我写了一篇关于这一点的文章。 一个很好的选项可能是只使用命令行标志。 有一些 JSON 方言专为人类编写而设计：JSON5，Hjson 和 HOCON。所有这些似乎都是对标准 JSON 的合理改进，尽管我没有用过它们中的任何一个。特别是 JSON5 似乎是个不错的选项，因为它对 JSON 的改动最少。 我不愿提供其它选项，因为我没有对所有格式（ YAML 除外）进行深入评估；只是看看规范可能无法找出潜在的缺点（ YAML 就是个很好的例子，它有很多微妙的行为）。我确实没有时间或是兴趣去对所有选项做全面深入的审查。","categories":[{"name":"翻译","slug":"翻译","permalink":"https://blog.sdjdd.com/categories/翻译/"}],"tags":[{"name":"JSON","slug":"JSON","permalink":"https://blog.sdjdd.com/tags/JSON/"}]}]}